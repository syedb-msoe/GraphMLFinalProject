{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0+cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages.\n",
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "# Helper function for visualization.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>studentId</th>\n",
       "      <th>greV</th>\n",
       "      <th>greQ</th>\n",
       "      <th>greA</th>\n",
       "      <th>cgpa</th>\n",
       "      <th>univName</th>\n",
       "      <th>major</th>\n",
       "      <th>program</th>\n",
       "      <th>decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>157.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.59</td>\n",
       "      <td>New York University (NYU) - Steinhardt</td>\n",
       "      <td>Communication Sciences And Disorders</td>\n",
       "      <td>MS</td>\n",
       "      <td>Accepted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>157.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.57</td>\n",
       "      <td>Texas A&amp;M University</td>\n",
       "      <td>International Affairs</td>\n",
       "      <td>MS</td>\n",
       "      <td>Accepted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>155.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.66</td>\n",
       "      <td>University Of California, Irvine</td>\n",
       "      <td>Biotechnology Management</td>\n",
       "      <td>MS</td>\n",
       "      <td>Accepted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>161.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>Psychology</td>\n",
       "      <td>MS</td>\n",
       "      <td>Accepted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>149.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.68</td>\n",
       "      <td>New York University (NYU) Steinhardt</td>\n",
       "      <td>Speech Language Pathology (Online)</td>\n",
       "      <td>MS</td>\n",
       "      <td>Accepted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   studentId   greV   greQ  greA  cgpa  \\\n",
       "0          7  157.0  147.0   4.0  3.59   \n",
       "1         17  157.0  151.0   5.5  3.57   \n",
       "2         46  155.0  167.0   4.0  3.66   \n",
       "3         64  161.0  157.0   4.0  3.10   \n",
       "4         70  149.0  157.0   3.0  3.68   \n",
       "\n",
       "                                 univName  \\\n",
       "0  New York University (NYU) - Steinhardt   \n",
       "1                    Texas A&M University   \n",
       "2        University Of California, Irvine   \n",
       "3                       Boston University   \n",
       "4    New York University (NYU) Steinhardt   \n",
       "\n",
       "                                  major program  decision  \n",
       "0  Communication Sciences And Disorders      MS  Accepted  \n",
       "1                 International Affairs      MS  Accepted  \n",
       "2              Biotechnology Management      MS  Accepted  \n",
       "3                            Psychology      MS  Accepted  \n",
       "4    Speech Language Pathology (Online)      MS  Accepted  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_file = \"./data/Processed_data.csv\"\n",
    "student_data = pd.read_csv(student_file)\n",
    "student_data.head()\n",
    "student_data.drop(student_data.columns[student_data.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "student_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniId</th>\n",
       "      <th>univName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>New York University (NYU) - Steinhardt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Texas A&amp;M University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>University Of California, Irvine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Boston University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>New York University (NYU) Steinhardt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uniId                                univName\n",
       "0      1  New York University (NYU) - Steinhardt\n",
       "1      2                    Texas A&M University\n",
       "2      3        University Of California, Irvine\n",
       "3      4                       Boston University\n",
       "4      5    New York University (NYU) Steinhardt"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_students = len(student_data)\n",
    "n_uni = len((student_data['univName']).unique())\n",
    "uni_names = student_data.univName.unique()\n",
    "uni_data = pd.DataFrame(uni_names, columns=['univName'])\n",
    "uni_data['uniId'] = range(1, n_uni + 1)\n",
    "uni_data = uni_data[['uniId', 'univName']]\n",
    "uni_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "uni_dict = dict(zip(range(1, n_uni + 1), uni_names))\n",
    "uni_temp = dict(zip(uni_names, range(1, n_uni + 1)))\n",
    "arr = []\n",
    "for i in range(n_students):\n",
    "    arr.append(uni_temp.get(student_data.univName[i]))\n",
    "student_dict = dict(zip(student_data.studentId, student_data.cgpa))\n",
    "overall_data = pd.DataFrame(student_data.studentId, columns=['studentId'])\n",
    "overall_data['GPA'] = student_data.cgpa\n",
    "overall_data['uniId'] = arr\n",
    "overall_data['uniName'] = student_data.univName\n",
    "overall_data.head()\n",
    "overall_data.to_csv('./data/overall_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(torch.nn.Module):\n",
    "    def __init__(self, n_students, n_uni, n_factors = 20):\n",
    "        super().__init__()\n",
    "        # create student embeddings\n",
    "        self.student_factors = torch.nn.Embedding(n_students, n_factors)\n",
    "        # create university embeddings\n",
    "        self.uni_factors = torch.nn.Embedding(n_uni, n_factors)\n",
    "        self.student_factors.weight.data.uniform_(0, 0.05)\n",
    "        self.uni_factors.weight.data.uniform_(0, 0.05)\n",
    "    def forward(self, data):\n",
    "        # matrix multiplication\n",
    "        students, universities = data[:, 2], data[:, 3]\n",
    "        return(self.student_factors(students) * self.uni_factors(universities)).sum(1)\n",
    "    def predict(self, student, uni):\n",
    "        return self.forward(student, uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataloader (necessary for PyTorch)\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader # package that helps transform your data to machine learning readiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = overall_data.copy()\n",
    "        \n",
    "        students = overall_data.studentId.unique()\n",
    "        unis = overall_data.uniId.unique()\n",
    "        \n",
    "        print(students)\n",
    "        print(unis)\n",
    "        \n",
    "        self.stuId2idx = {o:i for i,o in enumerate(students)}\n",
    "        self.uniId2idx = {o:i for i,o in enumerate(unis)}\n",
    "        \n",
    "        self.idx2stuId = {i:o for o,i in self.stuId2idx.items()}\n",
    "        self.idx2uniId = {i:o for o,i in self.uniId2idx.items()}\n",
    "        \n",
    "        self.data.uniId = overall_data.uniId.apply(lambda x: self.uniId2idx[x])\n",
    "        self.data.studentId = overall_data.studentId.apply(lambda x: self.stuId2idx[x])\n",
    "        \n",
    "        self.data.head()\n",
    "        self.x = self.data['uniId'].values\n",
    "        self.y = self.data['GPA'].values\n",
    "        \n",
    "        self.x = torch.tensor(self.x)\n",
    "        self.y = torch.tensor(self.y)\n",
    "    def __getuni__(self, index):\n",
    "        return(self.x[index], self.y[index])\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0+cpu\n",
      "[    7    17    46 ... 12644 12743 12787]\n",
      "[   1    2    3 ... 3671 3672 3673]\n"
     ]
    }
   ],
   "source": [
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "model = MatrixFactorization(n_students, n_uni, n_factors=8)\n",
    "train_set = Loader()\n",
    "train_loader = DataLoader(train_set, 128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is running on GPU: False\n",
      "student_factors.weight tensor([[0.0376, 0.0302, 0.0285,  ..., 0.0113, 0.0315, 0.0244],\n",
      "        [0.0131, 0.0468, 0.0085,  ..., 0.0453, 0.0039, 0.0450],\n",
      "        [0.0098, 0.0195, 0.0034,  ..., 0.0181, 0.0169, 0.0152],\n",
      "        ...,\n",
      "        [0.0480, 0.0060, 0.0181,  ..., 0.0114, 0.0240, 0.0150],\n",
      "        [0.0065, 0.0232, 0.0327,  ..., 0.0457, 0.0234, 0.0459],\n",
      "        [0.0093, 0.0086, 0.0336,  ..., 0.0017, 0.0244, 0.0068]])\n",
      "uni_factors.weight tensor([[0.0421, 0.0305, 0.0059,  ..., 0.0423, 0.0295, 0.0431],\n",
      "        [0.0126, 0.0090, 0.0149,  ..., 0.0379, 0.0230, 0.0458],\n",
      "        [0.0401, 0.0418, 0.0461,  ..., 0.0280, 0.0255, 0.0090],\n",
      "        ...,\n",
      "        [0.0145, 0.0066, 0.0380,  ..., 0.0320, 0.0259, 0.0499],\n",
      "        [0.0261, 0.0479, 0.0339,  ..., 0.0240, 0.0129, 0.0182],\n",
      "        [0.0174, 0.0376, 0.0415,  ..., 0.0184, 0.0313, 0.0010]])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[39mprint\u001b[39m(name, param\u001b[39m.\u001b[39mdata)\n\u001b[0;32m     20\u001b[0m \u001b[39m# GPU enable if you have a GPU...\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mcuda()\n\u001b[0;32m     23\u001b[0m \u001b[39m# MSE loss\u001b[39;00m\n\u001b[0;32m     24\u001b[0m loss_fn \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mMSELoss()\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:747\u001b[0m, in \u001b[0;36mModule.cuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m    731\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[0;32m    732\u001b[0m \n\u001b[0;32m    733\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[0;32m    746\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 747\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(\u001b[39mlambda\u001b[39;49;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:639\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    638\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 639\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    641\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    642\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    643\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    644\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    650\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:662\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    659\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    660\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    661\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 662\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    663\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    664\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:747\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m    731\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[0;32m    732\u001b[0m \n\u001b[0;32m    733\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[0;32m    746\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 747\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply(\u001b[39mlambda\u001b[39;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\cuda\\__init__.py:221\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    218\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 221\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    222\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    224\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# criterion = torch.nn.CrossEntropyLoss() # Define loss criterion.\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4) \n",
    "# def train():\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad() # Clear gradients.\n",
    "#     out = model(data.x) # Perform a single forward pass.\n",
    "#     loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "#     loss.backward() # Derive gradients.\n",
    "#     optimizer.step() # Update parameters based on gradients.\n",
    "#     return loss\n",
    "\n",
    "# for epoch in range(1, 201):\n",
    "#     loss = train()\n",
    "# print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "cuda = torch.cuda.is_available()\n",
    "print(\"Is running on GPU:\", cuda)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "# GPU enable if you have a GPU...\n",
    "model = model.cuda()\n",
    "\n",
    "# MSE loss\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# ADAM optimizier\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster #0\n",
      "\t University Of Michigan\n",
      "\t Northwestern University\n",
      "\t Purdue University\n",
      "\t Georgetown University\n",
      "\t University Of Houston\n",
      "\t University Of Maryland\n",
      "\t University Of Alberta\n",
      "\t Yale University\n",
      "\t University Of Kentucky\n",
      "\t University Of California, Berkeley (UCB)\n",
      "Cluster #1\n",
      "\t Columbia University\n",
      "\t Cornell University\n",
      "\t UCLA\n",
      "\t University Of Pittsburgh\n",
      "\t University Of South Florida\n",
      "\t Washington University in St. Louis (WashU/WUSTL)\n",
      "\t New York University (NYU)\n",
      "\t University Of Arizona\n",
      "\t Western Michigan University\n",
      "\t Columbia  University\n",
      "Cluster #2\n",
      "\t University Of Pennsylvania\n",
      "\t New York University\n",
      "\t University Of Texas At Dallas\n",
      "\t University Of Virginia\n",
      "\t University Of Central Florida\n",
      "\t Johns Hopkins University\n",
      "\t University Of Georgia\n",
      "\t Clemson University\n",
      "\t University Of Kansas\n",
      "\t Illinois State University\n",
      "Cluster #3\n",
      "\t Arizona State University\n",
      "\t Carnegie Mellon University (CMU)\n",
      "\t Towson University\n",
      "\t University Of Oxford\n",
      "\t à¸µUniversity Of Maryland - College Park (UMD)\n",
      "\t University Of Texas At Austin (UT Austin)\n",
      "\t San Diego State University (SDSU)\n",
      "\t Columbia  University (Fu Foundation)\n",
      "\t University Of Denver\n",
      "\t Hofstra University\n",
      "Cluster #4\n",
      "\t University Of Washington\n",
      "\t Northeastern University\n",
      "\t Syracuse University\n",
      "\t North Carolina State University\n",
      "\t University Of California, San Diego\n",
      "\t Adelphi University\n",
      "\t UCSD (University Of California, San Diego)\n",
      "\t University Of Delaware\n",
      "\t University Of Pennsylvania (UPenn)\n",
      "\t San Diego State University\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# Fit the clusters based on the movie weights\n",
    "trained_uni_embeddings = model.uni_factors.weight.data.cpu().numpy()\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(trained_uni_embeddings)\n",
    "for cluster in range(5):\n",
    "    print(\"Cluster #{}\".format(cluster))\n",
    "    unis = []\n",
    "    for uniIdx in np.where(kmeans.labels_ == cluster)[0]:\n",
    "        uniId = train_set.idx2uniId[uniIdx]\n",
    "        gpa_count = overall_data.loc[overall_data['uniId']==uniId].count()[0]\n",
    "        unis.append((uni_dict[uniId], gpa_count))\n",
    "    for uni in sorted(unis, key=lambda tup: tup[1], reverse=True)[:10]:\n",
    "        print(\"\\t\", uni[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
